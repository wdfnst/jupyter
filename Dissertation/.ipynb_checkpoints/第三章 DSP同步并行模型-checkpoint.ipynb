{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第三章 DSP同步并行模型\n",
    "DSP模型的目标就是在不影响算法收敛的前提下,通过减少算法迭代轮数,进而减少算法在通信上的开销,从而加速 算法的收敛.为实现这个目标,我们发现,不同于稠密依赖关系数据集上的迭代计算,稀疏依赖关系数据集上的迭代计算拥有更小的计算通信比:$T_{computation} / T_{communication}$,即迭代时间主要花在通信上,而非计算上.因此减少通信时间开销可以有效的加速并行算法的收敛.此外,我们还发现仅仅一步局部计算很难充分挖掘和利用数据分区内的局部性.对于一大类 图并行算法来讲,每次局部计算对应一次局部值传递,因而多步局部计算意味着多步局部值传递.然而,投机计算步并非越多越好,因为投机计算步是以增加计算量为代价,当集群节点之间的初始负载不均时,太多的投机计算步甚至会加剧节点 间负载不均.\n",
    "\n",
    "分析表明DSP的投机计算步的计算结果有如下两个特性:(i)尝试在数据分区内通过更充分的挖掘和利用空间局部性,实现空间局部性最优;(ii)尝试在一个超级计算步内通过更多的执行投机计算步实现超级计算步内的时间局部性最优.简而言之,DSP通过执行合理数量的投机计算步实现时间和空间上的局部最优.如果这里的空间和时间局部最优正好发生在某些适合的算法或作用于稀疏数据集上,那么它极有可能转化为最终和全局的最优.\n",
    "\n",
    "除此之外,DSP还具有一些其他优点.如(i)当其应用于值传递算法时,可同时适用于稠密和稀疏数据集;(ii)当应用于加速雅各比迭代时,其展现出了类似于超松弛(Successive Over-Relaxation,简称SOR)[21]的加速效果,既同时减少了局部计算步和全局迭代步数."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 相关工作\n",
    "\n",
    "#### 3.1.1 BSP模型\n",
    "Leslie Valiant于1990年在牛津大学提出了BSP并行模型.BSP模型主要用于指导设计同步并行算法和程序, BSP模型的一个重要意义在于它提出了一套建模分布式算法复杂度的模型.\n",
    "\n",
    "一个BSP算法或程序可以由如下三部分组成和表示:\n",
    "- **局部计算(Local Computation)**\n",
    "    \n",
    "- **通信(Communication)**:    \n",
    "    不少并行系统将通信视为参与者之间的个体行为, 即相互之间的消息发送和接收或内存之间的相互拷贝. 与之不同的是BSP将参与者之间的通信视为一个整体. 这样无疑减少了描述通信的复杂度, 因为随着通信参与者数量的增加, 他们之间的交互的复杂度会呈指数级增加, 且很难指出其中单对通信是如何完成的以及他们的完成时间. 影响通信速度的因素主要归结为如下几点:    \n",
    "    - 通信协议\n",
    "    - 运算单元和通信网络的缓冲器\n",
    "    - 网络的路由策略\n",
    "    - BSP的运行时系统\n",
    "- **阻塞同步(Barrier Synchronization)**:    \n",
    "    尽管阻塞同步可能产生较大的开销, 但其优点是让通信变得简单可靠. 因为不会引入循环数据依赖, 从而可以有效的避免死锁(deadlock)和活锁(livelock). 同时, 使用多种形式的容错机制也变成了可能. 究其主要原因, 阻塞同步的开销主要受以下两点因素影响:\n",
    "    - 参与并行任务的进程完成时间的方差. 典型的例子是所有其他进程等待一个还需要很长时间才能完成任务的进程, 且这个进程还有大量的工作没完成. 这种由负载不均衡产生问题只能通过任务分配和服务器动态负载均衡来实现.\n",
    "    - 所有计算节点达到全局一致状态的成本. 这主要取决于通信网络, 网络中是否存在专用同步器件一起其他加速硬件. \n",
    "\n",
    "BSP算法的一个超级计算步可以描述为图1所展示的过程.\n",
    "<img src=\"image/bsp.png\" width=\"500\">\n",
    "\n",
    "BSP模型算法示意图如下示.\n",
    "```python\n",
    "procedure DSP_algo(X):\n",
    "    iter_count == 0\n",
    "    while True do:\n",
    "        Computing()\n",
    "        if iter_count % delta == 0 then:\n",
    "            DataExchange()\n",
    "            if is_convergent() then:\n",
    "                break\n",
    "        iter_count++\n",
    "```\n",
    "\n",
    "BSP所建模的分布式算法复杂度取决于三部分的加和, 即局部计算最长耗时, 进程间全局通信耗时和阻塞同步耗时. 其中, 进程$p$的耗时可公式化为: $$max_{(i=1)}^p(w_i) + max_{(i=1)}^p(h_ig) + l \\tag{3.1.1.1} $$ 其中, $w_i$为进程$i$局部计算的时间开销, $h_i$为进程$i$发送或接收的消息数, $g$为发送或接收一个单位数据的耗时, $l$为阻塞同步的开销. 式(3.1.1.1)的前提假设为同构处理环境, 更一般的复杂度描述可表示为: $$w + hg + l,$$ 其中, $w, l$为对应量的最大值. 那么, 算法执行的总共时间开销可表示为: $$\\displaystyle W + Hg + Sl = \\Sigma_{s=1}^Sw_s + g\\Sigma_{s=1}^Sh_s + Sl,$$ 其中, $S$为超级计算步的数目.\n",
    "\n",
    "\n",
    "#### 3.1.2 参数服务器\n",
    "为解决大规模分布式机器学习中数以百万计的参数频繁更新的问题,Google在2012年提出了参数服务器的方案[15].参数服务器允许各个模型副本在一个很小的时间间隔内异步的上传和下载中心化参数服务器中的最新参数.这样一来,各个模型副本就可以减少使用参数服务器时互斥等待的时间.虽然,在允许的时间间隔内,模型副本从参数服务器上获取的数据并不一致,但最后算法还是可以收敛.在Google的论文[15]中展示了参数服务器惊人的加速性能,然而,其同时也表达了其对加速原理的不解.进一步工作[15–19],分别将参数服务器用来加速不用的应用,并部分给出了收敛性证明.然而到目前为止,还没有人给出一个参数服务器正确性的一般性证明,亦或是使用范围的约束条件.更何况,在一些极端的情形下,参数服务器可能致使算法出错或不收敛.与参数服务器不同的是,DSP算法除了支持一大类机器学习算法之外,DSP从根本上是针对并行迭代计算提出的模型,因此几乎可以适应所有的并行迭代计算.并且,针对其适用性和正确性,我们给出了一般性证明和使用约束条件.\n",
    "\n",
    "另外,参数服务器的相关工作并没有解释其加速的原理,本文中对DSP加速的原理解释同样适用于解释参数服务器加速的原理.\n",
    "\n",
    "<img src=\"image/parameterserver.jpeg\" width=\"500\">\n",
    "\n",
    "#### 3.1.3 KLA\n",
    "K层异步算法(K-Level Asynchronous,简称KLA)[20], 其目标是将层次同步范式(level-synchronous paradigm)和异步并行范式(asynchronous paradigm)进行融合. 作者这样做的动机是想在通过增加局部同步来减少全局同步, 毕竟全局同步比局部同步开销大得多. 实际上可以将KLA视为一种同步和异步混合执行的模式, 参数K限定了每执行多少步异步计算对应执行一次全局同步. 这种做法首先要求算法的执行过程具有层次性, 如广度优先的图遍历, 其次, 对于很大一部分算法(如PageRank), KLA并不能保证算出正确的答案, 或者即使能算出正确的答案也需要更大的计算和通信开销.\n",
    "\n",
    "DSP与KLA的不同主要体现在以下几点:\n",
    "- DSP仅仅在大同步时才进行节点间的通讯,而KLA在局部计算时也会进行节点间通信.因而DSP比KLA更简单,同时也 具备比KLA更好的可扩展性和适用范围.试验中我们发现,通信的开销不仅仅与通信的次数相关,同时还受到消息长 度的极大影响.\n",
    "- DSP的应用不限于KLA所局限的图计算领域.\n",
    "- DSP既不是KLA的特例,KLA也不是DSP的特例.\n",
    "\n",
    "#### 3.1.4 多步并行最短路算法\n",
    "多步并行最短路算法(∆-stepping: a parallelizable shortest path algorithm)[21, 22]是单源最短路算法的一种改进算法. 它通过维护一个待选顶点的列表, 每次向前尝试性地进行∆步迭代. 从而投机地向前前进多步.\n",
    "\n",
    "DSP并不需要显示的维护这样一个列表和待选数据, 只需要在数据分区中简单重复地执行相同的操作并更新局部数据, 却可以达到和KLA相同的效果. DSP用于加速单源最短路算法的示意图可见图6.\n",
    "\n",
    "#### 3.1.5 其他工作\n",
    "投机计算(Spective Computation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 DSP模型\n",
    "\n",
    "#### 3.2.1 动机(Motivation): 为了什么样的目的?\n",
    "- **迭代路径长, 收敛速度慢**    \n",
    "顶点数300万左右的web图, 在一定收敛精度下, PageRank约需要50轮迭代可以达到收敛. 同样在单源最短路算法中, 路网(road network)一般都具有较大的图直径, 这就导致最短路算法需要进行较多轮数的迭代才能收敛. 像PageRank, SSSP这类算法, 其典型特点是计算量少(Computation-light), 通信量大. 无论在高性能计算集群, 还是商用计算集群(Commodity Cluster)上, 通信都将占据整个执行时间的较大比例. \n",
    "\n",
    "- **商用计算集群(Commodity Cluster)上, 全局同步代价大**    \n",
    "与高性能计算集群不同的是商用计算集群的节点之间通信延迟较大, 数据传输和阻塞同步耗时较多. 而高性能计算集群通过高性能网络组件(如InfiniBand等)使节点间通信延迟降低到最小. 尽管如此, 即使采用高性能集群也会面临新的问题, 如对节点的计算资源利用率低. 且节点间负载存不均衡的话, 快的计算节点将会一直空等待慢的计算节点. 这样对于计算量小的并行迭代任务, 通信和阻塞同步的开销仍然会占到较大比例.\n",
    "\n",
    "为说明计算量小的并行迭代算法计算和通信时间的比例, 并比较高性能计算集群和商用集群在通信延迟上差距, 我们进行了一组实验来说明. 实验结果如下表:\n",
    "\n",
    "|序号|  算法名称 |    商用机群   | 高性能集群 |\n",
    "|---|----------|-------------|------|\n",
    "| 1 | PageRank | 任务1,2      |33.33%|\n",
    "| 2 |   SSSP   | 任务1,2      |33.33%|\n",
    "| 3 |  Jacobi  | 任务1,2      |33.33%|\n",
    "\n",
    "试验中, 我们分别采用了PageRank, SSSP算法和雅各比迭代求线性方程组, 结果显示....\n",
    "\n",
    "- **异步计算虽然速度快, 但是构造异步算法太复杂; 同步计算虽然简单, 但是慢.**    \n",
    "异步计算在处理速度上相比同步计算具有明显的优势. 但异步计算除了在运行中会消耗更多的无用计算和通信外, 最大的问题在于异步算法相对难于设计, 且没有统一的适合所有应用的异步并行模式, 即对不不用应用需要设计不同的异步算法. 异步算法的难点在于资源竞争(resource race), 临界区控制以及结束条件设定和控制等.    \n",
    "即使设计出异步算法, 其正确性验证也有非常多的工作并难以实现. 分析异步算法正确性时, 需要考虑不同进程以不同速度运行时所产生的不同输出. 为简化分析, 一种典型做法是假设每个单独指令的执行具有原子性, 即允许在所有指令交错的情况下考虑顺序语义(To simplify this analysis one typically assumes that individual instructions take place atomically allowing one to consider the sequential semantics under all possible interleavings of the instructions). 即使采用了这种简化, 正确性分析也同样面临困难, 因为产生情况的数据可能是交错数目的指数级.\n",
    "\n",
    "#### 3.2.2 洞悉真相(Insight): 其中的一些发现\n",
    "- **数据之间存在依赖性, 极端情况: 良好分图, 子图之间无依赖**    \n",
    "无论是是同步模型, 或是异步模型, 之所以要进行通信最终缘由是因为数据之间的依赖性. 而通信量的大小体现了数据之间依赖性的强弱, 除了与数据内存本身存在的依赖性之外, 数据的分割的方式也会直接导致通信量的不同. 一个典型例子如下图所示, 三种不同的分图方式导致三个计算节点间的通信截然不同.\n",
    "<img src=\"image/graphpartition.jpeg\" width=\"700\">\n",
    "\n",
    "- **数据之间依赖性的两面性:**    \n",
    " - **引入误差, 放慢收敛**:    \n",
    " 一般来讲在算法收敛的过程中, 引入误差将大概率致使算法收敛的轨迹偏离正确的收敛轨迹, 从而放慢收敛的速度.\n",
    " - **促进收敛****    \n",
    " 在算法收敛的过程中引入误差并不一定就会致使收敛速度放慢. 如在文献\\cite{hmm}中就证明和验证了这个结论. 那么, 本文尝试寻找一种并行模型的加速方法, 可以在保证算法大致收敛轨迹的前提下, 减少通信. 即在误差受控的前提下, 少通信或不通信地推进算法的收敛. \n",
    "- **同步BSP模型的一般化, $\\Delta$=1时, 退化为BSP模型.**    \n",
    "由如上几段的分析可知, 如果能找到这样一种方法使收敛路径保持大致不变(误差受控), 且保证收敛结果正确的话, 我们就可以通过减少通信从而加速算法的收敛.\n",
    "\n",
    "#### 3.2.3 直觉(Intuition): 感觉上那样做可以加速, 并且是正确的.\n",
    "- **优化算法, 或更一般的迭代计算, 迭代式不唯一**     \n",
    "从最优化相关理论可得知, 一个优化问题的递推公式或迭代式通常都不唯一, 并且都可以得到问题的解, 甚至最优解(通常要求优化问题为凸问题). 而影响迭代速度的主要是迭代的方向和步长, 虽然可以通过求解一个子最优化问题得到最优的迭代步长, 但一般由于代价过大都通过依据经验确定的超参数或自适应的解析式.    \n",
    "- **最坏情况, 即使放慢, 但仍然正确:**    \n",
    "有许多理论和准则来约束和保证迭代算法最终是否能够收敛, 如Armijo准则, Goldstein准则, Wolfe准则.\n",
    "\n",
    "#### 3.2.4 灵感来源(Inspiration)\n",
    "- **投机计算**    \n",
    "投机计算一种计算优化方法, 通过提前计算还未确切知道需要与否的计算, 旨在减少某项确切需要进行工作的延迟. 副作用是可能进行一些无用计算. 通过3.2.2小节的分析, 我们猜测保持算法迭代路径大致不变的计算可能与投机计算所选用的计算类似.\n",
    "\n",
    "- **将迭代计算的问题统一视为优化问题**        \n",
    "若将并行模型中的应用视为优化问题, 那么我们也可以采用不同的迭代步长来达到同样的优化效果. 如何在迭代计算中将\"步长\"的概念引入进来, 并证明其有效性和正确性是本文的核心贡献.\n",
    "\n",
    "#### 3.2.5 基于BSP的改进\n",
    "对比BSP, DSP只是简单地将单步局部计算变为∆步局部计算(∆ ≥ 1), 每步局部计算和之前的局部计算仍做一样的操作. DSP算法的一个超级计算步可以描述为图2所示的过程.同时我们将额外增加的∆ − 1步局部计算称之为投机计算步(Speculative Computation Step, 简称SCStep), 其定义如下:\n",
    "\n",
    "**投机计算步(SCStep)** 重复执行BSP的局部计算步,只做局部数据更新,期间无数据通信发生.\n",
    "\n",
    "<img src=\"image/dsp.jpeg\" width=\"800\">\n",
    "\n",
    "DSP模型算法示意图如下示.\n",
    "```python\n",
    "procedure DSP_algo(X):\n",
    "    iter_count == 0\n",
    "    while True do:\n",
    "        Computing()\n",
    "        if iter_count % delta == 0 then:\n",
    "            DataExchange()\n",
    "            if is_convergent() then:\n",
    "                break\n",
    "        iter_count++\n",
    "```\n",
    "\n",
    "#### 3.2.6 为什么将局部计算视为\"迭代的步长\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 DSP模型的形式化表示\n",
    "\n",
    "#### 3.3.1 为什么要形式化表示\n",
    "方法实用化的中心问题是效率和正确性保证. 通过应用于实际算法和数据集, DSP的加速效果已经得到了充分的验证. 而正确性除了从直观上理解外, 同时也需要数学语言来进行更严密的表示和证明. 本节解决的问题就是采用第二章中提出的形式化表达方法来表示DSP模型的迭代过程.\n",
    "\n",
    "#### 3.3.2 注意点\n",
    "\n",
    "根据第二章中变量和运算符的定义, 我们首先表示出$\\Delta$步局部计算和更新的表达式. 再将每步具有$\\Delta$步局部计算的$l$步大同步计算表示如下:\n",
    "\n",
    "\\begin{align*}\n",
    "% \\vspace*{-\\baselineskip}\\setlength\\belowdisplayshortskip{0pt}\n",
    "X_{t0} &= (x_{t0,0}, x_{t0,1}, \\dots, x_{t0,n})  \\\\\n",
    "X_{t1}^{(p, q)} &= X_{t0}\\otimes F^{(p, q)} = (x_{t0,0}, x_{t0,1}, \\dots, x_{t0,n})\\otimes\n",
    "        \\begin{pmatrix}\n",
    "          1 & 0 & \\dots & 0 & F_{0,p} & \\dots & F_{0,q} & 0 & \\dots & 0 \\\\\n",
    "          0 & 1 & \\dots & 0 & F_{1,p} & \\dots & F_{1,q} & 0 & \\dots & 0 \\\\\n",
    "          \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "          0 & 0 & \\dots & 1 & F_{p-1,p} & \\dots & F_{p-1,q} & 0 & \\dots & 0 \\\\\n",
    "          0 & 0 & \\dots & 0 & F_{p,p} & \\dots & F_{p,q} & 0 & \\dots & 0 \\\\\n",
    "          \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "          0 & 0 & \\dots & 0 & F_{q,p} & \\dots & F_{q,q} & 0 & \\dots & 0 \\\\\n",
    "          0 & 0 & \\dots & 0 & F_{q+1,p} & \\dots & F_{q+1,q} & 1 & \\dots & 0 \\\\\n",
    "          \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "          0 & 0 & \\dots & 0 & F_{n,p} & \\dots & F_{n,q} & 0 & \\dots & 1 \\\\\n",
    "        \\end{pmatrix} \\\\\n",
    "&= (x_{t0,0},\\dots,~x_{t0,p-1},~\\biguplus_{i=0}^{n}F_{i, p}(x_{t0,i}),~\\biguplus_{i=0}^{n}F_{i, p+1}(x_{t0,i}),~\\dots,~\\biguplus_{i=0}^{n}F_{i, q}(x_{t0,i}),~x_{t0,q+1},~\\dots,~x_{t0,n}) \\\\\n",
    " X_{t2}^{(p, q)}  &= X_{t1}^{(p, q)}\\otimes F^{(p, q)} \\\\\n",
    " %%%%%%%%%%%%%%%%%%%% Add the arrow and tex explain\n",
    " &= (x_{t0,0},\\dots,~x_{t0,p-1},~\\biguplus_{i=0}^{n}F_{i, p}(x_{t1,i}),~\\biguplus_{i=0}^{n}F_{i, p+1}(x_{t1,i}),~\\dots,~\\biguplus_{i=0}^{n}F_{i, q}(x_{t1,i}),~x_{t0,q+1},~\\dots,~x_{t0,n}) \\\\\n",
    "&=(x_{t0,0},\\dots,~x_{t0,p-1},~ \\biguplus_{}^{}(\\underset{i\\in(p,q)}{\\biguplus}F_{i,p}(\\biguplus_{i=0}^{n}F_{i,p}(x_{t0,i})),~\\underset{i\\notin(p,q)}{\\biguplus}F_{i,p}(x_{t0,i})), \\\\\n",
    " &\\quad\\quad\\quad\\quad\\quad~\\dots,~\\biguplus_{}^{}(\\underset{i\\in(p,q)}{\\biguplus}F_{i,q}(\\biguplus_{i=0}^{n}F_{i,q}(x_{t0,i})),~\\underset{i\\notin(p,q)}{\\biguplus}F_{i,q}(x_{t0,i})),~x_{t0,q+1},~\\dots,x_{t0,n}) \\\\\n",
    "&=(x_{t0,0},\\dots,~x_{t0,p-1},~\\biguplus(\\biguplus_{i\\in(p,q)}F_{i,p}(\\alpha_p),\\beta_p),~\\dots,~\\biguplus(\\biguplus_{i\\in(p,q)}F_{i,q}(\\alpha_q),\\beta_q),~x_{t0,q+1},~\\dots,x_{t0,n}) \\\\\n",
    "&=(x_{t0,0},\\dots,~x_{t0,p-1},~g(\\alpha_p, \\beta_p),~\\dots,~g(\\alpha_q, \\beta_q),~x_{t0,q+1},~\\dots,x_{t0,n}) \\\\\n",
    "X_{t3}^{(p, q)} &= X_{t2}^{(p, q)}\\otimes F^{(p, q)} \\\\\n",
    "&= (x_{t0,0},\\dots,~x_{t0,p-1},~\\biguplus(\\biguplus_{i\\in(p,q)}^{}F_{i,p}\\biguplus(\\biguplus_{i\\in(p,q)}F_{i,p}(\\alpha_p),~\\beta_p),~\\beta_p), \\\\\n",
    "&\\quad\\quad\\quad\\quad\\quad~\\dots,~\\biguplus(\\biguplus_{i\\in(p,q)}^{}F_{i,q}\\biguplus(\\biguplus_{i\\in(p,q)}F_{i,q}(\\alpha_p),~\\beta_q),~\\beta_q),~x_{t0,q+1},~\\dots,x_{t0,n}) \\\\\n",
    "&= (x_{t0,0},\\dots,~x_{t0,p-1},~\\biguplus(\\biguplus_{i\\in(p,q)}^{}F_{i,p}(g(\\alpha_p,\\beta_p)),~\\beta_p),~\\dots,~\\biguplus(\\biguplus_{i\\in(p,q)}^{}F_{i,q}(g(\\alpha_q,\\beta_q)),~\\beta_q),~x_{t0,q+1},~x_{t0,q+1},~\\dots,x_{t0,n}) \\\\\n",
    "      & \\vdots \\\\\n",
    "X_{\\Delta}^{(p, q)} &= X_{\\Delta-1}^{(p, q)}\\otimes F^{(p, q)} \\\\\n",
    "&= (x_{t0,0},\\dots,~x_{t0,p-1},~\\biguplus(\\biguplus_{i\\in(p,q)}F_{i,p}(\\dots\\biguplus(\\biguplus_{i\\in(p,q)}F_{i,p}(\\alpha_p),~\\beta_p),\\dots,\\beta_p),\\beta_p), \\\\\n",
    "&\\quad\\quad\\quad\\quad~\\dots,~\\biguplus(\\biguplus_{i\\in(p,q)}F_{i,q}(\\dots\\biguplus(\\biguplus_{i\\in(p,q)}F_{i,q}(\\alpha_q),~\\beta_q),\\dots,\\beta_q),\\beta_q),~x_{t0,q+1},~\\dots,~x_{t0,n}) \\\\\n",
    "&= (x_{t0,0},\\dots,~x_{t0,p-1},~g(g(\\dots g(\\alpha_p,\\beta_p),\\dots,\\beta_p),\\beta_p),\\dots,~g(g(\\dots g(\\alpha_q,\\beta_q),\\dots,\\beta_q),\\beta_q),~x_{t0,q+1},\\dots,x_{t0,n}) \\\\\n",
    "&= (x_{t0,0},\\dots,~x_{t0,p-1},g^{\\Delta-1}(\\alpha_p,\\beta_p),\\dots,~g^{\\Delta-1}(\\alpha_q,\\beta_q),~x_{t0,q+1},\\dots,x_{t0,n})\n",
    "\\end{align*}\n",
    "\n",
    "其中, \n",
    "\\begin{align*}\n",
    "g(\\alpha_p,\\beta_p)&=\\biguplus(\\underset{i\\in(p,q)}{\\biguplus}F_{i,j}(\\alpha_p),~\\beta_p), \\\\ \n",
    "\\alpha_p&=\\overset{n}{\\underset{i=0}{\\biguplus}}F_{i,p}(x_{t0,i}), \\\\\n",
    "\\beta_p&=\\underset{i\\notin(p,q)}{\\biguplus}F_{i,p}(x_{t0,i}), \\\\\n",
    "p&=0,1,2,...,n.\n",
    "\\end{align*}\n",
    "\n",
    "公式中的参数直观上可以如下理解:\n",
    "- $g(\\alpha_p, \\beta_p)$: 将BSP中一次局部计算变为两次局部计算之后新算法.\n",
    "- $\\alpha_p$: 聚合$x_p$所有依赖的变量对其作用的结果.%从$x_p$所有依赖的分量聚合其计算结果之后的结果.\n",
    "- $\\beta_p$: 聚合$x_p$所依赖的且位于不同节点上的变量对其作用的结果.直观上看,$\\beta_p$表示$x_p$对其他分区数据的依赖程度.%从$x_p$所有依赖且位于不同处理节点上的变量聚合的结果.\n",
    "- $\\gamma_p$($=\\alpha_p-\\beta_p$): 聚合$x_p$所依赖的且位于相同节点上的变量对其作用的结果.直观上看,$\\gamma_p$可表示$x_p$对分区内部数据依赖的程度."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 DSP模型的收敛性证明\n",
    "包括参数服务器和DSP模型在内的许多算法\\cite{Prabhu2010Safe, Burton1985Speculative, Sohn1994Parallel, Sohn1995Parallel}都使用了投机计算的思想.然而,他们中许多并没有给出其适用性和正确性证明或施用条件.从而,用户在选用这些方法时,保持着谨慎的态度.本节,我们将给出BSP和DSP的关系,并推导出DSP收敛的条件.\n",
    "\n",
    "**定理一** 如果算法在BSP模式下能够收敛,那么,当且仅当满足如下条件时,算法在DSP模式下也收敛:   \n",
    "<p align=\"center\">\n",
    "算法$g(\\alpha_p,\\beta_p)$在BSP模型下收敛.\n",
    "</p>   \n",
    "(直观上讲,定理\\ref{theorem:dsp}描述了在BSP模式下收敛的算法,如果$\\Delta=2$时新算法仍然收敛,那么,它对于所有$\\Delta>2$也收敛.)\n",
    "\n",
    "\n",
    "```\n",
    "\\begin{proof}\n",
    "当$\\Delta=1$时,DSP模型退化为BSP模型.所以,$\\Delta=1$时,结论成立. \\\\\n",
    "假设当$\\Delta=k, k\\geq 1$时,结论成立,即: \\[h^{l}(g^{k-1}(\\alpha_p,~\\beta_p))\\tag{a}\\] 能够收敛. \\\\\n",
    "那么,当$\\Delta=k+1$时,(a)式可变为如下左式,并变形为右式:\n",
    "\\begin{align}\n",
    "h^{l}(g^{k}(\\alpha_p,~\\beta_p)) = h^{l}(g^{k-1}(g(\\alpha_p,~\\beta_p), \\beta_p))\\tag{b}\n",
    "\\end{align}\n",
    "% Compare (b) with (a), (a) converges because $\\alpha_p$ is a convergent operation under BSP model. So the convergence condition for (b) is: \\[g(\\alpha_p,\\beta_p) ~converges ~under ~BSP ~model.\\tag{4.3}\\]\n",
    "对比(a),(b)式,(a)式收敛是因为$\\alpha_p$在BSP模式下收敛.所以,(b)式收敛的条件是: \\\\\n",
    "\\centerline{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad算法$g(\\alpha_p,\\beta_p)$在BSP模型下收敛.\\hfill (4.3)}  %\\label{eq:4.3}\n",
    "% \\[g(\\alpha_p,\\beta_p) ~converges ~under ~BSP ~model.\\tag{4.3}\\]\n",
    "在满足条件4.3时,定理\\ref{theorem:dsp}对$\\Delta=k+1$成立.  \\\\\n",
    "由数学归纳法的原理可知,在满足条件4.3时,定理\\ref{theorem:dsp}对所有$\\Delta \\in \\mathbb{N}$成立.\n",
    "\\end{proof}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 DSP模型加速性能分析\n",
    "由公式\\[g^{\\Delta-1}(\\alpha_p, \\beta_p),\\] 我们发现,DSP算法的收敛主要依赖三个因素:$\\Delta, \\alpha_p$和$\\beta_p$(其中,$p=0, 1, 2,\\cdots,n.$).进一步,它们和收敛速度之间有如下关系:\n",
    "\n",
    "- 当$\\beta_p=0$时(即是说$x_p$的收敛不依赖任何位于其他运算节点上的变量),$x_p$的收敛可以不需要任何全局数据同步.这时,额外的$\\Delta-1$步投机计算可以获得非常显著的加速,以致于当$\\Delta$充分大时,$x_p$可以在不需要任何全局同步的情况下直接收敛.图\\ref{fig:alphabetagamma}(a)展示了这种情况,每个数据分区被分配到不同的计算节点,彼此之间也不存在依赖关系,这个图上的并行迭代计算可以在不需要任何全局数据同步的情况下收敛. \n",
    "- 当$\\gamma_p=0$时(即是说$x_p$的收敛完全依赖于位于其他节点上的变量),因为$\\Delta$步局部计算$x_p$所依赖的值并不会更新,所以,$\\Delta$次局部计算产生的新值也不会有任何变化.如图\\ref{fig:alphabetagamma}(c)展示了这种情况,图中每个分区中的节点所依赖的变量全部位于其他计算节点内,这种情况下,额外的$\\Delta-1$次局部计算不会产生任何加速效果.\n",
    "- 当$\\gamma_p>0$时(即是说$x_p$所依赖的变量部分位于和自己相同的节点内),额外的$\\Delta-1$步计算会促进$x_p$更快地收敛.并且,加速效果和$\\gamma_p$成正比.\n",
    "- 当$\\beta_p>0$时(即是说$x_p$所依赖的变量部分位于其他节点),第一次局部计算之后,$\\beta_p$并没有及时从其他节点获取最新值进行更新,剩下的$\\Delta-1$步局部计算都是使用上次全局同步的$\\beta_p$.过期的$\\beta_p$对$x_p$的收敛可能其起反作用.并且我们认为$\\beta_p$的大小与$x_p$的收敛速度成反比.如图\\ref{fig:alphabetagamma}(b)展示了这种情况,每个数据分区内的数据所依赖的数据既有来自本节点的也有来自其他节点上的.\n",
    "\n",
    "从某种意义上讲,$\\gamma_p$和$\\beta_p$可以分别用数据分区内部和数据分区之间依赖关系的密度来解释.所以,如果可以通过适当的数据划分来增加分区内依赖关系密度(增大$\\alpha_p$),同时减小分区间依赖关系密度(减小$\\beta_p$),那么算法的收敛就可能得到加速.不幸的是完美的数据切分(如图划分)通常都是NP难问题.尽管增大$\\gamma_p$是困难,足够小的$\\beta_p$却是非常常见的,因为稀疏数据集划分之后,$\\beta_p$通常都会非常小,这就为我们使用DSP加速迭代运算创造了条件.\n",
    "\n",
    "为验证$\\beta_p$,$\\gamma_p$与加速效果之间的关系,我们使用PageRank算法在随机图上进行了两组实验:(a)固定子图内的连接度,变化子图之间的连接度;(b)固定子图间的连接度,变化子图内部的连接度.\n",
    "\n",
    "实验结果如图\\ref{fig:gammabeta}所示,子图(a)显示加速比$Iteration_{bsp}/Iteration_{dsp}$随着增加的$\\beta$而下降,即子图间连接增加后,DSP的加速性能下降了.子图(b)显示加速比$Iteration_{bsp}/Iteration_{dsp}$随着增加的$\\gamma$而上升,即子图内连接增加后,DSP的加速性能上升了.这一结果和我们上面的分析是一致的.(至于子图(a)中开始阶段不正常的趋势,我们认为是因为赋予图的初始连接度太小,以致于任何连接度的增加都会导致收敛的加快.)\n",
    "\n",
    "<img src=\"image/betagamma.jpeg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 DSP算法的构造\n",
    "对比算法1,2,不难发现将BSP算法改造为DSP算法或直接构造DSP算法都是比较容易实现的.DSP程序和BSP程序唯 一不同在于DSP在进行全局通信前增加了一个检测条件(测试是否执行了指定步数的局部计算).构造DSP程序时,我们可 按照如下几步进行:\n",
    "- 如果BSP算法的递推公式收敛,那么检验拥有两步局部计算的递推公式是否收敛,如果收敛则转到第2)步,否则,采用其他方式考察该算法是否适合用DSP进行加速;    \n",
    "- 筛选合适的参数∆;    \n",
    "- 调整代码.增加过滤条件使得每执行一次DataExchange()对应执行∆次Computing().    \n",
    "\n",
    "对各种算法,并没有普遍适用的∆值.根据IV-C中的分析,当数据集比较稀疏或采用较好的数据切分方法时,可以选用 适当大的∆,反之,适当的小的∆更受推荐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 参数$\\Delta$的选择\n",
    "从上文的分析中可得知, 一般情况下参数$\\Delta$并非越大越好, 过大的$\\Delta$不仅会引入过多的无用计算, 加重计算负担, 更重要的是可能引入太大的误差, 从而使计算轨迹偏离原来的收敛轨迹过大. 那么如何选择一个合适的数值是本节讨论的主题.\n",
    "\n",
    "对各种算法,并没有普遍适用的∆值.根据IV-C中的分析,当数据集比较稀疏或采用较好的数据切分方法时,可以选用 适当大的∆,反之,适当的小的∆更受推荐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 总结\n",
    "通过.    \n",
    "DSP模型提出既是偶然实验的产物, 也是多个领域(并行计算, 优化方法和数值计算)理论研究和发现的结果. 它不仅结合了并行计算中模型开发, 最优化方法的迭代步长优化和数值计算中的不动点迭代, 同时还涉及到投机计算和误差控制."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
