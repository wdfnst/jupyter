{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第三章 DSP同步并行模型\n",
    "DSP模型的目标就是在不影响算法收敛的前提下,通过减少算法迭代轮数,进而减少算法在通信上的开销,从而加速 算法的收敛.为实现这个目标,我们发现,不同于稠密依赖关系数据集上的迭代计算,稀疏依赖关系数据集上的迭代计算拥有更小的计算通信比:$T_{computation} / T_{communication}$,即迭代时间主要花在通信上,而非计算上.因此减少通信时间开销可以有效的加速并行算法的收敛.此外,我们还发现仅仅一步局部计算很难充分挖掘和利用数据分区内的局部性.对于一大类 图并行算法来讲,每次局部计算对应一次局部值传递,因而多步局部计算意味着多步局部值传递.然而,投机计算步并非越多越好,因为投机计算步是以增加计算量为代价,当集群节点之间的初始负载不均时,太多的投机计算步甚至会加剧节点 间负载不均.\n",
    "\n",
    "分析表明DSP的投机计算步的计算结果有如下两个特性:(i)尝试在数据分区内通过更充分的挖掘和利用空间局部性,实现空间局部性最优;(ii)尝试在一个超级计算步内通过更多的执行投机计算步实现超级计算步内的时间局部性最优.简而言之,DSP通过执行合理数量的投机计算步实现时间和空间上的局部最优.如果这里的空间和时间局部最优正好发生在某些适合的算法或作用于稀疏数据集上,那么它极有可能转化为最终和全局的最优.\n",
    "\n",
    "除此之外,DSP还具有一些其他优点.如(i)当其应用于值传递算法时,可同时适用于稠密和稀疏数据集;(ii)当应用于加速雅各比迭代时,其展现出了类似于超松弛(Successive Over-Relaxation,简称SOR)[21]的加速效果,既同时减少了局部计算步和全局迭代步数."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 相关工作\n",
    "\n",
    "#### 3.1.1 BSP模型\n",
    "Leslie Valiant于1990年在牛津大学提出了BSP并行模型.BSP模型主要用于指导设计同步并行算法和程序, BSP模型的一个重要意义在于它提出了一套建模分布式算法复杂度的模型.\n",
    "\n",
    "一个BSP算法或程序可以由如下三部分组成和表示:\n",
    "- **局部计算(Local Computation)**\n",
    "    \n",
    "- **通信(Communication)**:    \n",
    "    不少并行系统将通信视为参与者之间的个体行为, 即相互之间的消息发送和接收或内存之间的相互拷贝. 与之不同的是BSP将参与者之间的通信视为一个整体. 这样无疑减少了描述通信的复杂度, 因为随着通信参与者数量的增加, 他们之间的交互的复杂度会呈指数级增加, 且很难指出其中单对通信是如何完成的以及他们的完成时间. 影响通信速度的因素主要归结为如下几点:    \n",
    "    - 通信协议\n",
    "    - 运算单元和通信网络的缓冲器\n",
    "    - 网络的路由策略\n",
    "    - BSP的运行时系统\n",
    "- **阻塞同步(Barrier Synchronization)**:    \n",
    "    尽管阻塞同步可能产生较大的开销, 但其优点是让通信变得简单可靠. 因为不会引入循环数据依赖, 从而可以有效的避免死锁(deadlock)和活锁(livelock). 同时, 使用多种形式的容错机制也变成了可能. 究其主要原因, 阻塞同步的开销主要受以下两点因素影响:\n",
    "    - 参与并行任务的进程完成时间的方差. 典型的例子是所有其他进程等待一个还需要很长时间才能完成任务的进程, 且这个进程还有大量的工作没完成. 这种由负载不均衡产生问题只能通过任务分配和服务器动态负载均衡来实现.\n",
    "    - 所有计算节点达到全局一致状态的成本. 这主要取决于通信网络, 网络中是否存在专用同步器件一起其他加速硬件. \n",
    "\n",
    "BSP算法的一个超级计算步可以描述为图1所展示的过程.\n",
    "<img src=\"image/bsp.png\" width=\"500\">\n",
    "\n",
    "BSP模型算法示意图如下示.\n",
    "```python\n",
    "procedure DSP_algo(X):\n",
    "    iter_count == 0\n",
    "    while True do:\n",
    "        Computing()\n",
    "        if iter_count % delta == 0 then:\n",
    "            DataExchange()\n",
    "            if is_convergent() then:\n",
    "                break\n",
    "        iter_count++\n",
    "```\n",
    "\n",
    "BSP所建模的分布式算法复杂度取决于三部分的加和, 即局部计算最长耗时, 进程间全局通信耗时和阻塞同步耗时. 其中, 进程$p$的耗时可公式化为: $$max_{(i=1)}^p(w_i) + max_{(i=1)}^p(h_ig) + l \\tag{3.1.1.1} $$ 其中, $w_i$为进程$i$局部计算的时间开销, $h_i$为进程$i$发送或接收的消息数, $g$为发送或接收一个单位数据的耗时, $l$为阻塞同步的开销. 式(3.1.1.1)的前提假设为同构处理环境, 更一般的复杂度描述可表示为: $$w + hg + l,$$ 其中, $w, l$为对应量的最大值. 那么, 算法执行的总共时间开销可表示为: $$\\displaystyle W + Hg + Sl = \\Sigma_{s=1}^Sw_s + g\\Sigma_{s=1}^Sh_s + Sl,$$ 其中, $S$为超级计算步的数目.\n",
    "\n",
    "\n",
    "#### 3.1.2 参数服务器\n",
    "为解决大规模分布式机器学习中数以百万计的参数频繁更新的问题,Google在2012年提出了参数服务器的方案[15].参数服务器允许各个模型副本在一个很小的时间间隔内异步的上传和下载中心化参数服务器中的最新参数.这样一来,各个模型副本就可以减少使用参数服务器时互斥等待的时间.虽然,在允许的时间间隔内,模型副本从参数服务器上获取的数据并不一致,但最后算法还是可以收敛.在Google的论文[15]中展示了参数服务器惊人的加速性能,然而,其同时也表达了其对加速原理的不解.进一步工作[15–19],分别将参数服务器用来加速不用的应用,并部分给出了收敛性证明.然而到目前为止,还没有人给出一个参数服务器正确性的一般性证明,亦或是使用范围的约束条件.更何况,在一些极端的情形下,参数服务器可能致使算法出错或不收敛.与参数服务器不同的是,DSP算法除了支持一大类机器学习算法之外,DSP从根本上是针对并行迭代计算提出的模型,因此几乎可以适应所有的并行迭代计算.并且,针对其适用性和正确性,我们给出了一般性证明和使用约束条件.\n",
    "\n",
    "另外,参数服务器的相关工作并没有解释其加速的原理,本文中对DSP加速的原理解释同样适用于解释参数服务器加速的原理.\n",
    "\n",
    "<img src=\"image/parameterserver.jpeg\" width=\"500\">\n",
    "\n",
    "#### 3.1.3 KLA\n",
    "K层异步算法(K-Level Asynchronous,简称KLA)[20], 其目标是将层次同步范式(level-synchronous paradigm)和异步并行范式(asynchronous paradigm)进行融合. 作者这样做的动机是想在通过增加局部同步来减少全局同步, 毕竟全局同步比局部同步开销大得多. 实际上可以将KLA视为一种同步和异步混合执行的模式, 参数K限定了每执行多少步异步计算对应执行一次全局同步. 这种做法首先要求算法的执行过程具有层次性, 如广度优先的图遍历, 其次, 对于很大一部分算法(如PageRank), KLA并不能保证算出正确的答案, 或者即使能算出正确的答案也需要更大的计算和通信开销.\n",
    "\n",
    "DSP与KLA的不同主要体现在以下几点:\n",
    "- DSP仅仅在大同步时才进行节点间的通讯,而KLA在局部计算时也会进行节点间通信.因而DSP比KLA更简单,同时也 具备比KLA更好的可扩展性和适用范围.试验中我们发现,通信的开销不仅仅与通信的次数相关,同时还受到消息长 度的极大影响.\n",
    "- DSP的应用不限于KLA所局限的图计算领域.\n",
    "- DSP既不是KLA的特例,KLA也不是DSP的特例.\n",
    "\n",
    "#### 3.1.4 多步并行最短路算法\n",
    "多步并行最短路算法(∆-stepping: a parallelizable shortest path algorithm)[21, 22]是单源最短路算法的一种改进算法. 它通过维护一个待选顶点的列表, 每次向前尝试性地进行∆步迭代. 从而投机地向前前进多步.\n",
    "\n",
    "DSP并不需要显示的维护这样一个列表和待选数据, 只需要在数据分区中简单重复地执行相同的操作并更新局部数据, 却可以达到和KLA相同的效果. DSP用于加速单源最短路算法的示意图可见图6.\n",
    "\n",
    "#### 3.1.5 其他工作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 DSP模型\n",
    "对比BSP, DSP只是简单地将单步局部计算变为∆步局部计算(∆ ≥ 1), 每步局部计算和之前的局部计算仍做一样的操作. DSP算法的一个超级计算步可以描述为图2所示的过程.同时我们将额外增加的∆ − 1步局部计算称之为投机计算步(Speculative Computation Step, 简称SCStep), 其定义如下:\n",
    "\n",
    "**投机计算步(SCStep)** 重复执行BSP的局部计算步,只做局部数据更新,期间无数据通信发生.\n",
    "\n",
    "<img src=\"image/dsp.jpeg\" width=\"800\">\n",
    "\n",
    "DSP模型算法示意图如下示.\n",
    "```python\n",
    "procedure DSP_algo(X):\n",
    "    iter_count == 0\n",
    "    while True do:\n",
    "        Computing()\n",
    "        if iter_count % delta == 0 then:\n",
    "            DataExchange()\n",
    "            if is_convergent() then:\n",
    "                break\n",
    "        iter_count++\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 DSP模型的形式化表示\n",
    "\n",
    "根据第二章中变量和运算符的定义, 我们首先表示出$\\Delta$步局部计算和更新的表达式. 再将每步具有$\\Delta$步局部计算的$l$步大同步计算表示如下:\n",
    "\n",
    "\\begin{align*}\n",
    "% \\vspace*{-\\baselineskip}\\setlength\\belowdisplayshortskip{0pt}\n",
    "X_{t0} &= (x_{t0,0}, x_{t0,1}, \\dots, x_{t0,n})  \\\\\n",
    "X_{t1}^{(p, q)} &= X_{t0}\\otimes F^{(p, q)} = (x_{t0,0}, x_{t0,1}, \\dots, x_{t0,n})\\otimes\n",
    "        \\begin{pmatrix}\n",
    "          1 & 0 & \\dots & 0 & F_{0,p} & \\dots & F_{0,q} & 0 & \\dots & 0 \\\\\n",
    "          0 & 1 & \\dots & 0 & F_{1,p} & \\dots & F_{1,q} & 0 & \\dots & 0 \\\\\n",
    "          \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "          0 & 0 & \\dots & 1 & F_{p-1,p} & \\dots & F_{p-1,q} & 0 & \\dots & 0 \\\\\n",
    "          0 & 0 & \\dots & 0 & F_{p,p} & \\dots & F_{p,q} & 0 & \\dots & 0 \\\\\n",
    "          \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "          0 & 0 & \\dots & 0 & F_{q,p} & \\dots & F_{q,q} & 0 & \\dots & 0 \\\\\n",
    "          0 & 0 & \\dots & 0 & F_{q+1,p} & \\dots & F_{q+1,q} & 1 & \\dots & 0 \\\\\n",
    "          \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "          0 & 0 & \\dots & 0 & F_{n,p} & \\dots & F_{n,q} & 0 & \\dots & 1 \\\\\n",
    "        \\end{pmatrix} \\\\\n",
    "&= (x_{t0,0},\\dots,~x_{t0,p-1},~\\biguplus_{i=0}^{n}F_{i, p}(x_{t0,i}),~\\biguplus_{i=0}^{n}F_{i, p+1}(x_{t0,i}),~\\dots,~\\biguplus_{i=0}^{n}F_{i, q}(x_{t0,i}),~x_{t0,q+1},~\\dots,~x_{t0,n}) \\\\\n",
    " X_{t2}^{(p, q)}  &= X_{t1}^{(p, q)}\\otimes F^{(p, q)} \\\\\n",
    " %%%%%%%%%%%%%%%%%%%% Add the arrow and tex explain\n",
    " &= (x_{t0,0},\\dots,~x_{t0,p-1},~\\biguplus_{i=0}^{n}F_{i, p}(x_{t1,i}),~\\biguplus_{i=0}^{n}F_{i, p+1}(x_{t1,i}),~\\dots,~\\biguplus_{i=0}^{n}F_{i, q}(x_{t1,i}),~x_{t0,q+1},~\\dots,~x_{t0,n}) \\\\\n",
    "&=(x_{t0,0},\\dots,~x_{t0,p-1},~ \\biguplus_{}^{}(\\underset{i\\in(p,q)}{\\biguplus}F_{i,p}(\\biguplus_{i=0}^{n}F_{i,p}(x_{t0,i})),~\\underset{i\\notin(p,q)}{\\biguplus}F_{i,p}(x_{t0,i})), \\\\\n",
    " &\\quad\\quad\\quad\\quad\\quad~\\dots,~\\biguplus_{}^{}(\\underset{i\\in(p,q)}{\\biguplus}F_{i,q}(\\biguplus_{i=0}^{n}F_{i,q}(x_{t0,i})),~\\underset{i\\notin(p,q)}{\\biguplus}F_{i,q}(x_{t0,i})),~x_{t0,q+1},~\\dots,x_{t0,n}) \\\\\n",
    "&=(x_{t0,0},\\dots,~x_{t0,p-1},~\\biguplus(\\biguplus_{i\\in(p,q)}F_{i,p}(\\alpha_p),\\beta_p),~\\dots,~\\biguplus(\\biguplus_{i\\in(p,q)}F_{i,q}(\\alpha_q),\\beta_q),~x_{t0,q+1},~\\dots,x_{t0,n}) \\\\\n",
    "&=(x_{t0,0},\\dots,~x_{t0,p-1},~g(\\alpha_p, \\beta_p),~\\dots,~g(\\alpha_q, \\beta_q),~x_{t0,q+1},~\\dots,x_{t0,n}) \\\\\n",
    "X_{t3}^{(p, q)} &= X_{t2}^{(p, q)}\\otimes F^{(p, q)} \\\\\n",
    "&= (x_{t0,0},\\dots,~x_{t0,p-1},~\\biguplus(\\biguplus_{i\\in(p,q)}^{}F_{i,p}\\biguplus(\\biguplus_{i\\in(p,q)}F_{i,p}(\\alpha_p),~\\beta_p),~\\beta_p), \\\\\n",
    "&\\quad\\quad\\quad\\quad\\quad~\\dots,~\\biguplus(\\biguplus_{i\\in(p,q)}^{}F_{i,q}\\biguplus(\\biguplus_{i\\in(p,q)}F_{i,q}(\\alpha_p),~\\beta_q),~\\beta_q),~x_{t0,q+1},~\\dots,x_{t0,n}) \\\\\n",
    "&= (x_{t0,0},\\dots,~x_{t0,p-1},~\\biguplus(\\biguplus_{i\\in(p,q)}^{}F_{i,p}(g(\\alpha_p,\\beta_p)),~\\beta_p),~\\dots,~\\biguplus(\\biguplus_{i\\in(p,q)}^{}F_{i,q}(g(\\alpha_q,\\beta_q)),~\\beta_q),~x_{t0,q+1},~x_{t0,q+1},~\\dots,x_{t0,n}) \\\\\n",
    "      & \\vdots \\\\\n",
    "X_{\\Delta}^{(p, q)} &= X_{\\Delta-1}^{(p, q)}\\otimes F^{(p, q)} \\\\\n",
    "&= (x_{t0,0},\\dots,~x_{t0,p-1},~\\biguplus(\\biguplus_{i\\in(p,q)}F_{i,p}(\\dots\\biguplus(\\biguplus_{i\\in(p,q)}F_{i,p}(\\alpha_p),~\\beta_p),\\dots,\\beta_p),\\beta_p), \\\\\n",
    "&\\quad\\quad\\quad\\quad~\\dots,~\\biguplus(\\biguplus_{i\\in(p,q)}F_{i,q}(\\dots\\biguplus(\\biguplus_{i\\in(p,q)}F_{i,q}(\\alpha_q),~\\beta_q),\\dots,\\beta_q),\\beta_q),~x_{t0,q+1},~\\dots,~x_{t0,n}) \\\\\n",
    "&= (x_{t0,0},\\dots,~x_{t0,p-1},~g(g(\\dots g(\\alpha_p,\\beta_p),\\dots,\\beta_p),\\beta_p),\\dots,~g(g(\\dots g(\\alpha_q,\\beta_q),\\dots,\\beta_q),\\beta_q),~x_{t0,q+1},\\dots,x_{t0,n}) \\\\\n",
    "&= (x_{t0,0},\\dots,~x_{t0,p-1},g^{\\Delta-1}(\\alpha_p,\\beta_p),\\dots,~g^{\\Delta-1}(\\alpha_q,\\beta_q),~x_{t0,q+1},\\dots,x_{t0,n})\n",
    "\\end{align*}\n",
    "\n",
    "其中, \n",
    "\\begin{align*}\n",
    "g(\\alpha_p,\\beta_p)&=\\biguplus(\\underset{i\\in(p,q)}{\\biguplus}F_{i,j}(\\alpha_p),~\\beta_p), \\\\ \n",
    "\\alpha_p&=\\overset{n}{\\underset{i=0}{\\biguplus}}F_{i,p}(x_{t0,i}), \\\\\n",
    "\\beta_p&=\\underset{i\\notin(p,q)}{\\biguplus}F_{i,p}(x_{t0,i}), \\\\\n",
    "p&=0,1,2,...,n.\n",
    "\\end{align*}\n",
    "\n",
    "公式中的参数直观上可以如下理解:\n",
    "- $g(\\alpha_p, \\beta_p)$: 将BSP中一次局部计算变为两次局部计算之后新算法.\n",
    "- $\\alpha_p$: 聚合$x_p$所有依赖的变量对其作用的结果.%从$x_p$所有依赖的分量聚合其计算结果之后的结果.\n",
    "- $\\beta_p$: 聚合$x_p$所依赖的且位于不同节点上的变量对其作用的结果.直观上看,$\\beta_p$表示$x_p$对其他分区数据的依赖程度.%从$x_p$所有依赖且位于不同处理节点上的变量聚合的结果.\n",
    "- $\\gamma_p$($=\\alpha_p-\\beta_p$): 聚合$x_p$所依赖的且位于相同节点上的变量对其作用的结果.直观上看,$\\gamma_p$可表示$x_p$对分区内部数据依赖的程度."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 DSP模型的收敛性证明\n",
    "包括参数服务器和DSP模型在内的许多算法\\cite{Prabhu2010Safe, Burton1985Speculative, Sohn1994Parallel, Sohn1995Parallel}都使用了投机计算的思想.然而,他们中许多并没有给出其适用性和正确性证明或施用条件.从而,用户在选用这些方法时,保持着谨慎的态度.本节,我们将给出BSP和DSP的关系,并推导出DSP收敛的条件.\n",
    "\n",
    "**定理一** 如果算法在BSP模式下能够收敛,那么,当且仅当满足如下条件时,算法在DSP模式下也收敛:   \n",
    "<p align=\"center\">\n",
    "算法$g(\\alpha_p,\\beta_p)$在BSP模型下收敛.\n",
    "</p>   \n",
    "(直观上讲,定理\\ref{theorem:dsp}描述了在BSP模式下收敛的算法,如果$\\Delta=2$时新算法仍然收敛,那么,它对于所有$\\Delta>2$也收敛.)\n",
    "\n",
    "\n",
    "```\n",
    "\\begin{proof}\n",
    "当$\\Delta=1$时,DSP模型退化为BSP模型.所以,$\\Delta=1$时,结论成立. \\\\\n",
    "假设当$\\Delta=k, k\\geq 1$时,结论成立,即: \\[h^{l}(g^{k-1}(\\alpha_p,~\\beta_p))\\tag{a}\\] 能够收敛. \\\\\n",
    "那么,当$\\Delta=k+1$时,(a)式可变为如下左式,并变形为右式:\n",
    "\\begin{align}\n",
    "h^{l}(g^{k}(\\alpha_p,~\\beta_p)) = h^{l}(g^{k-1}(g(\\alpha_p,~\\beta_p), \\beta_p))\\tag{b}\n",
    "\\end{align}\n",
    "% Compare (b) with (a), (a) converges because $\\alpha_p$ is a convergent operation under BSP model. So the convergence condition for (b) is: \\[g(\\alpha_p,\\beta_p) ~converges ~under ~BSP ~model.\\tag{4.3}\\]\n",
    "对比(a),(b)式,(a)式收敛是因为$\\alpha_p$在BSP模式下收敛.所以,(b)式收敛的条件是: \\\\\n",
    "\\centerline{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad算法$g(\\alpha_p,\\beta_p)$在BSP模型下收敛.\\hfill (4.3)}  %\\label{eq:4.3}\n",
    "% \\[g(\\alpha_p,\\beta_p) ~converges ~under ~BSP ~model.\\tag{4.3}\\]\n",
    "在满足条件4.3时,定理\\ref{theorem:dsp}对$\\Delta=k+1$成立.  \\\\\n",
    "由数学归纳法的原理可知,在满足条件4.3时,定理\\ref{theorem:dsp}对所有$\\Delta \\in \\mathbb{N}$成立.\n",
    "\\end{proof}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 DSP模型加速性能分析\n",
    "由公式\\[g^{\\Delta-1}(\\alpha_p, \\beta_p),\\] 我们发现,DSP算法的收敛主要依赖三个因素:$\\Delta, \\alpha_p$和$\\beta_p$(其中,$p=0, 1, 2,\\cdots,n.$).进一步,它们和收敛速度之间有如下关系:\n",
    "\n",
    "- 当$\\beta_p=0$时(即是说$x_p$的收敛不依赖任何位于其他运算节点上的变量),$x_p$的收敛可以不需要任何全局数据同步.这时,额外的$\\Delta-1$步投机计算可以获得非常显著的加速,以致于当$\\Delta$充分大时,$x_p$可以在不需要任何全局同步的情况下直接收敛.图\\ref{fig:alphabetagamma}(a)展示了这种情况,每个数据分区被分配到不同的计算节点,彼此之间也不存在依赖关系,这个图上的并行迭代计算可以在不需要任何全局数据同步的情况下收敛. \n",
    "- 当$\\gamma_p=0$时(即是说$x_p$的收敛完全依赖于位于其他节点上的变量),因为$\\Delta$步局部计算$x_p$所依赖的值并不会更新,所以,$\\Delta$次局部计算产生的新值也不会有任何变化.如图\\ref{fig:alphabetagamma}(c)展示了这种情况,图中每个分区中的节点所依赖的变量全部位于其他计算节点内,这种情况下,额外的$\\Delta-1$次局部计算不会产生任何加速效果.\n",
    "- 当$\\gamma_p>0$时(即是说$x_p$所依赖的变量部分位于和自己相同的节点内),额外的$\\Delta-1$步计算会促进$x_p$更快地收敛.并且,加速效果和$\\gamma_p$成正比.\n",
    "- 当$\\beta_p>0$时(即是说$x_p$所依赖的变量部分位于其他节点),第一次局部计算之后,$\\beta_p$并没有及时从其他节点获取最新值进行更新,剩下的$\\Delta-1$步局部计算都是使用上次全局同步的$\\beta_p$.过期的$\\beta_p$对$x_p$的收敛可能其起反作用.并且我们认为$\\beta_p$的大小与$x_p$的收敛速度成反比.如图\\ref{fig:alphabetagamma}(b)展示了这种情况,每个数据分区内的数据所依赖的数据既有来自本节点的也有来自其他节点上的.\n",
    "\n",
    "从某种意义上讲,$\\gamma_p$和$\\beta_p$可以分别用数据分区内部和数据分区之间依赖关系的密度来解释.所以,如果可以通过适当的数据划分来增加分区内依赖关系密度(增大$\\alpha_p$),同时减小分区间依赖关系密度(减小$\\beta_p$),那么算法的收敛就可能得到加速.不幸的是完美的数据切分(如图划分)通常都是NP难问题.尽管增大$\\gamma_p$是困难,足够小的$\\beta_p$却是非常常见的,因为稀疏数据集划分之后,$\\beta_p$通常都会非常小,这就为我们使用DSP加速迭代运算创造了条件.\n",
    "\n",
    "为验证$\\beta_p$,$\\gamma_p$与加速效果之间的关系,我们使用PageRank算法在随机图上进行了两组实验:(a)固定子图内的连接度,变化子图之间的连接度;(b)固定子图间的连接度,变化子图内部的连接度.\n",
    "\n",
    "实验结果如图\\ref{fig:gammabeta}所示,子图(a)显示加速比$Iteration_{bsp}/Iteration_{dsp}$随着增加的$\\beta$而下降,即子图间连接增加后,DSP的加速性能下降了.子图(b)显示加速比$Iteration_{bsp}/Iteration_{dsp}$随着增加的$\\gamma$而上升,即子图内连接增加后,DSP的加速性能上升了.这一结果和我们上面的分析是一致的.(至于子图(a)中开始阶段不正常的趋势,我们认为是因为赋予图的初始连接度太小,以致于任何连接度的增加都会导致收敛的加快.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 总结"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
